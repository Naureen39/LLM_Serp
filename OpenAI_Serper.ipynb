{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OpenAI + Serp API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook approaches to do the tasks for a prompt-driven microsite generation engine, specifically targeting the \"Promote\" use case. Each method is aligned with its respective deliverable, followed by observed outcomes and impact based on implementation results. The solution incorporates trend-aware context retrieval using a web search API with Retrieval-Augmented Generation (RAG) and leverages a lightweight language model for generating concise, skimmable microsites, optimized for cost and designed without bio-link dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NElMnF5jn6Hz",
        "outputId": "3fbc55e3-e8ce-4aec-f4c9-30b406692e85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet  langchain-community langchain-openai\n",
        "\n",
        "\n",
        "# hjfvdsgcv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aJqMymxn6K-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pprint\n",
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "\n",
        "os.environ[\"SERPER_API_KEY\"] = os.environ.get(\"SERPER_API_KEY\")\n",
        "\n",
        "search = GoogleSerperAPIWrapper()\n",
        "\n",
        "def call_serper_api(user_query):\n",
        "  search.run(user_query)\n",
        "  return search.run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWijNP_lf6nu"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from openai import OpenAI\n",
        "from typing import Optional, List\n",
        "\n",
        "# Set up your OpenAI credentials (or use environment variables)\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OpenAI_API_KEY\")\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(\n",
        "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        "    organization=os.environ.get(\"OpenAI_Organization_ID\"),           # Replace with your real org ID\n",
        "    project=os.environ.get(\"OpenAI_Project_ID\")           # Replace with your real project ID\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOoVi2wN3gka"
      },
      "source": [
        "# **Build prompt templates per intent (Sell, Promote, etc.) & Define JSON schema**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wj3ypZyBhkUY"
      },
      "outputs": [],
      "source": [
        "def build_prompt(intent: str,\n",
        "                 user_input: str,\n",
        "                 nano_output: Optional[dict] = None,\n",
        "                 retrieval_context: Optional[List[str]] = None) -> dict:\n",
        "    \"\"\"\n",
        "    Constructs a structured GPT prompt config for the given intent and inputs.\n",
        "    \"\"\"\n",
        "    system_prompt = \"\"\n",
        "    instructions = \"\"\n",
        "\n",
        "    if intent.lower() == \"promote\":\n",
        "        system_prompt = (\n",
        "            \"You are a microsite generation assistant. Your task is to create a short, structured promotional \"\n",
        "            \"microsite layout for a small business. Respond *only* in valid JSON. \" # Emphasize ONLY JSON\n",
        "            \"Each microsite must include 5 elements: informational, benefits, optional trend (if data provided), CTA, and testimonial. \"\n",
        "            \"Each element must have a 'type', 'title', and 'body'. Keep each body under 150 words, optimized for mobile.\"\n",
        "        )\n",
        "        instructions = (\n",
        "            \"Generate the JSON output now. \" # Explicitly ask for JSON now\n",
        "            \"If 'retrieval_context' is provided, use it to add a 'trend' element. \"\n",
        "            \"Format all output as a JSON object with 'intent': 'Promote' and a 5-element 'elements' array. \"\n",
        "            \"Ensure the output is just the JSON object, starting with '{'.\" # Guide the format\n",
        "        )\n",
        "\n",
        "    elif intent.lower() == \"sell\":\n",
        "        system_prompt = (\n",
        "            \"You are a microsite generator for product sales. Based on the input description and structured image analysis output, \"\n",
        "            \"generate a short, structured JSON microsite with a maximum of 5 elements. These must include: informational, features, \"\n",
        "            \"price, CTA, and testimonial. Keep all bodies under 150 words. Respond *only* in valid JSON.\" # Emphasize ONLY JSON\n",
        "        )\n",
        "        instructions = (\n",
        "            \"Generate the JSON output now. \" # Explicitly ask for JSON now\n",
        "            \"Use the image description, category, tags, and price estimate to build the microsite layout. \"\n",
        "            \"Return structured JSON only with 'intent': 'Sell' and an array of 5 elements. \"\n",
        "            \"Ensure the output is just the JSON object, starting with '{'.\" # Guide the format\n",
        "        )\n",
        "\n",
        "    elif intent.lower() == \"educate\":\n",
        "        system_prompt = (\n",
        "            \"You are a microsite content assistant focused on education. Create a 5-element microsite based on the topic provided. \"\n",
        "            \"Always include an informational intro, 3-point bullet list, trend (if data available), embed, and CTA. \"\n",
        "            \"Keep all content under 150 words each, clear, and scannable. Respond *only* in valid JSON.\" # Emphasize ONLY JSON\n",
        "        )\n",
        "        instructions = (\n",
        "            \"Generate the JSON output now. \" # Explicitly ask for JSON now\n",
        "            \"If retrieval_context is present, include it as a 'trend' element. \"\n",
        "            \"Output must be a JSON object with 'intent': 'Educate' and 5 elements. \"\n",
        "            \"Ensure the output is just the JSON object, starting with '{'.\" # Guide the format\n",
        "        )\n",
        "    else: # Handle unknown intents gracefully\n",
        "         logging.error(f\"Unknown intent: {intent}\")\n",
        "         return {\"system_prompt\": \"\", \"user_input\": user_input, \"instructions\": \"Invalid intent provided.\"}\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"system_prompt\": system_prompt,\n",
        "        \"user_input\": user_input,\n",
        "        \"nano_output\": nano_output,\n",
        "        \"retrieval_context\": retrieval_context,\n",
        "        \"instructions\": instructions\n",
        "    }\n",
        "\n",
        "def generate_microsite_with_gpt(prompt_config: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Makes a gpt-4o-mini call using OpenAI v1.x SDK and returns parsed JSON microsite.\n",
        "    Includes error handling for JSON parsing.\n",
        "    \"\"\"\n",
        "    if not prompt_config.get(\"system_prompt\"):\n",
        "        logging.error(\"Prompt configuration is incomplete or invalid.\")\n",
        "        return {}\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": prompt_config[\"system_prompt\"]},\n",
        "        {\"role\": \"user\", \"content\": prompt_config[\"user_input\"]}\n",
        "    ]\n",
        "\n",
        "    if prompt_config.get(\"retrieval_context\"):\n",
        "        messages.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Retrieved Context:\\n\" + \"\\n\".join(f\"- {line}\" for line in prompt_config[\"retrieval_context\"])\n",
        "        })\n",
        "\n",
        "    if prompt_config.get(\"nano_output\"):\n",
        "        messages.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Image Analysis:\\n{json.dumps(prompt_config['nano_output'], indent=2)}\"\n",
        "        })\n",
        "\n",
        "    messages.append({\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt_config[\"instructions\"]\n",
        "    })\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=messages,\n",
        "            temperature=0.5,\n",
        "            top_p=0.9,\n",
        "            max_tokens=400,\n",
        "            response_format={ \"type\": \"json_object\" } # Explicitly request JSON output type\n",
        "        )\n",
        "        content = response.choices[0].message.content.strip()\n",
        "\n",
        "        # Attempt to parse JSON\n",
        "        try:\n",
        "            return json.loads(content), response\n",
        "        except json.JSONDecodeError as e:\n",
        "            logging.error(f\"JSON Decode Error: {e}\")\n",
        "            logging.error(f\"Content received from API was: {content}\")\n",
        "            # Optionally save the bad content to a file for later inspection\n",
        "            # with open(\"bad_response.txt\", \"w\") as f:\n",
        "            #     f.write(content)\n",
        "            return {\"error\": \"Failed to parse JSON response from AI.\", \"raw_content\": content}\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error during OpenAI API call: {e}\")\n",
        "        return {\"error\": f\"OpenAI API call failed: {e}\"}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqWDtQaL7Ntd",
        "outputId": "8fe962ad-46ea-4e32-85e6-5a2f83ee2035"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"intent\": \"Promote\",\n",
            "  \"elements\": [\n",
            "    {\n",
            "      \"type\": \"informational\",\n",
            "      \"title\": \"Welcome to Sweet Treats Baking Studio\",\n",
            "      \"body\": \"Located in the heart of Austin, our home baking studio specializes in custom cakes for all occasions. Whether it's a birthday, wedding, or any celebration, we craft delicious and beautiful cakes tailored to your vision.\"\n",
            "    },\n",
            "    {\n",
            "      \"type\": \"benefits\",\n",
            "      \"title\": \"Why Choose Us?\",\n",
            "      \"body\": \"Our cakes are made from the finest ingredients, ensuring rich flavors and moist textures. We offer personalized designs, quick turnaround times, and a commitment to quality that will make your event unforgettable.\"\n",
            "    },\n",
            "    {\n",
            "      \"type\": \"trend\",\n",
            "      \"title\": \"Summer Baking Boom\",\n",
            "      \"body\": \"Home-based dessert businesses peak during summer due to high demand for custom cakes for events. This is the perfect time to order your cake and make your celebrations even sweeter!\"\n",
            "    },\n",
            "    {\n",
            "      \"type\": \"CTA\",\n",
            "      \"title\": \"Order Your Custom Cake Today!\",\n",
            "      \"body\": \"Ready to make your next event special? Visit our Instagram page to see our latest creations and DM us to place your order. Let\\u2019s bake something amazing together!\"\n",
            "    },\n",
            "    {\n",
            "      \"type\": \"testimonial\",\n",
            "      \"title\": \"What Our Customers Say\",\n",
            "      \"body\": \"\\u2018The cake was not only stunning but absolutely delicious! Sweet Treats made my birthday unforgettable. Highly recommend!\\u2019 - Sarah, Austin\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Build prompt for a \"Promote\" use case\n",
        "prompt_data = build_prompt(\n",
        "    intent=\"Promote\",\n",
        "    user_input=\"Promote my home baking studio in Austin to increase Instagram cake orders this summer.\",\n",
        "    retrieval_context=[\n",
        "        \"Home-based dessert businesses peak during summer due to custom event demand. (Reddit)\",\n",
        "        \"Instagram Reels showing behind-the-scenes baking have high engagement. (Quora)\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Call GPT to generate microsite\n",
        "microsite_json, response = generate_microsite_with_gpt(prompt_data)\n",
        "r=response\n",
        "# Display result\n",
        "print(json.dumps(microsite_json, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPSGJ8KQ0ii3"
      },
      "source": [
        "#**Performance & Cost Targets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs9DwsKPaVVl"
      },
      "source": [
        "**Prcing link:**\n",
        "\n",
        "https://openai.com/api/pricing/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNqh_B---CpO",
        "outputId": "2c8a09c7-e111-429e-c273-5d2e9c068745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Token Usage & Estimated Cost (GPT-4o Mini) ---\n",
            "Input Tokens     : 222\n",
            "Output Tokens    : 321\n",
            "Total Tokens     : 543\n",
            "Estimated Cost   : $0.008640 USD\n"
          ]
        }
      ],
      "source": [
        "# print(r.usage)\n",
        "# Cost configuration for GPT-4o Mini\n",
        "GPT4O_MINI_PRICING = {\n",
        "    \"prompt_token_cost\": 0.00001,    # $10 per million input tokens\n",
        "    \"completion_token_cost\": 0.00002 # $20 per million output tokens\n",
        "}\n",
        "\n",
        "def print_gpt4o_mini_cost(response):\n",
        "    usage = response.usage\n",
        "    input_tokens = usage.prompt_tokens\n",
        "    output_tokens = usage.completion_tokens\n",
        "    total_tokens = usage.total_tokens\n",
        "\n",
        "    # Calculate cost\n",
        "    cost = (\n",
        "        input_tokens * GPT4O_MINI_PRICING[\"prompt_token_cost\"] +\n",
        "        output_tokens * GPT4O_MINI_PRICING[\"completion_token_cost\"]\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- Token Usage & Estimated Cost (GPT-4o Mini) ---\")\n",
        "    print(f\"Input Tokens     : {input_tokens}\")\n",
        "    print(f\"Output Tokens    : {output_tokens}\")\n",
        "    print(f\"Total Tokens     : {total_tokens}\")\n",
        "    print(f\"Estimated Cost   : ${cost:.6f} USD\")\n",
        "print_gpt4o_mini_cost(r)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbFfw-rs9Vh2",
        "outputId": "8bad2e6f-cca0-4f15-c143-e0fffb9a0551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Microsite Intent: Promote\n",
            "\n",
            "Microsite Elements:\n",
            "\n",
            "--- Element 1 ---\n",
            "Type: informational\n",
            "Title: Welcome to Sweet Treats Baking Studio\n",
            "Body:\n",
            "Located in the heart of Austin, our home baking studio specializes in custom cakes for all occasions. Whether it's a birthday, wedding, or any celebration, we craft delicious and beautiful cakes tailored to your vision.\n",
            "\n",
            "--- Element 2 ---\n",
            "Type: benefits\n",
            "Title: Why Choose Us?\n",
            "Body:\n",
            "Our cakes are made from the finest ingredients, ensuring rich flavors and moist textures. We offer personalized designs, quick turnaround times, and a commitment to quality that will make your event unforgettable.\n",
            "\n",
            "--- Element 3 ---\n",
            "Type: trend\n",
            "Title: Summer Baking Boom\n",
            "Body:\n",
            "Home-based dessert businesses peak during summer due to high demand for custom cakes for events. This is the perfect time to order your cake and make your celebrations even sweeter!\n",
            "\n",
            "--- Element 4 ---\n",
            "Type: CTA\n",
            "Title: Order Your Custom Cake Today!\n",
            "Body:\n",
            "Ready to make your next event special? Visit our Instagram page to see our latest creations and DM us to place your order. Let’s bake something amazing together!\n",
            "\n",
            "--- Element 5 ---\n",
            "Type: testimonial\n",
            "Title: What Our Customers Say\n",
            "Body:\n",
            "‘The cake was not only stunning but absolutely delicious! Sweet Treats made my birthday unforgettable. Highly recommend!’ - Sarah, Austin\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Assuming microsite_json is the dictionary output from generate_microsite_with_gpt\n",
        "microsite_data = microsite_json\n",
        "\n",
        "# Check if the dictionary contains the expected structure\n",
        "if isinstance(microsite_data, dict) and \"intent\" in microsite_data and \"elements\" in microsite_data:\n",
        "    print(f\"Microsite Intent: {microsite_data['intent']}\")\n",
        "    print(\"\\nMicrosite Elements:\")\n",
        "\n",
        "    # Iterate through the list of elements\n",
        "    for i, element in enumerate(microsite_data[\"elements\"]):\n",
        "        print(f\"\\n--- Element {i+1} ---\")\n",
        "        # Extract type, title, and body from each element dictionary\n",
        "        element_type = element.get(\"type\", \"N/A\") # Use .get() for safe access\n",
        "        element_title = element.get(\"title\", \"N/A\")\n",
        "        element_body = element.get(\"body\", \"N/A\")\n",
        "\n",
        "        print(f\"Type: {element_type}\")\n",
        "        print(f\"Title: {element_title}\")\n",
        "        print(f\"Body:\\n{element_body}\")\n",
        "\n",
        "elif isinstance(microsite_data, dict) and \"error\" in microsite_data:\n",
        "    print(\"Error generating microsite:\")\n",
        "    print(f\"Error message: {microsite_data.get('error', 'Unknown error')}\")\n",
        "    print(f\"Raw content: {microsite_data.get('raw_content', 'No raw content')}\")\n",
        "\n",
        "else:\n",
        "    print(\"microsite_json is not a valid microsite dictionary.\")\n",
        "    print(f\"Type received: {type(microsite_json)}\")\n",
        "    print(f\"Content received: {microsite_json}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMu1nkgC3qXJ"
      },
      "source": [
        "#Implement layout logic engine to assemble microsite structure based on intent\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNOyEat_9tcf"
      },
      "outputs": [],
      "source": [
        "LAYOUT_RULES = {\n",
        "    \"sell\": [\"informational\", \"features\", \"price\", \"cta\", \"testimonial\"],\n",
        "    \"promote\": [\"informational\", \"benefits\", \"trend\", \"cta\", \"testimonial\"],\n",
        "    \"educate\": [\"informational\", \"bullet_points\", \"trend\", \"embed\", \"cta\"]\n",
        "}\n",
        "\n",
        "def get_layout_for_intent(intent: str) -> List[str]:\n",
        "    return LAYOUT_RULES.get(intent.lower(), [\"informational\", \"cta\", \"text\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMHkp8oMdcDr"
      },
      "outputs": [],
      "source": [
        "LAYOUT_RULES = {\n",
        "    \"sell\": [\"informational\", \"features\", \"price\", \"cta\", \"testimonial\"],\n",
        "    \"promote\": [\"informational\", \"benefits\", \"trend\", \"cta\", \"testimonial\"],\n",
        "    \"educate\": [\"informational\", \"bullet_points\", \"trend\", \"embed\", \"cta\"]\n",
        "}\n",
        "\n",
        "def get_layout_for_intent(intent: str) -> List[str]:\n",
        "    return LAYOUT_RULES.get(intent.lower(), [\"informational\", \"cta\", \"text\"])\n",
        "\n",
        "def build_prompt(intent: str,\n",
        "                 user_input: str,\n",
        "                 retrieval_context: Optional[List[str]] = None) -> dict:\n",
        "    \"\"\"\n",
        "    Builds the prompt with dynamic layout structure based on intent.\n",
        "    \"\"\"\n",
        "    system_prompt = (\n",
        "        \"You are a microsite generation assistant. \"\n",
        "        \"Return a structured JSON response for a microsite with 5 elements. \"\n",
        "        \"Each element must include: type, title, and body. Body must be <150 words.\"\n",
        "    )\n",
        "\n",
        "    layout = get_layout_for_intent(intent)\n",
        "    layout_instruction = \"\\n\".join([f\"{i+1}. {el.replace('_', ' ').title()}\" for i, el in enumerate(layout)])\n",
        "\n",
        "    retrieved_block = \"\"\n",
        "    if retrieval_context:\n",
        "        retrieved_block = \"Retrieved Context:\\n\" + \"\\n\".join(f\"- {s}\" for s in retrieval_context)\n",
        "\n",
        "    user_prompt = (\n",
        "        f\"Intent: {intent}\\n\"\n",
        "        f\"User Input: {user_input}\\n\\n\"\n",
        "        f\"{retrieved_block}\\n\\n\"\n",
        "        f\"Microsite layout:\\n{layout_instruction}\\n\\n\"\n",
        "        f\"Respond in the following JSON format:\\n\"\n",
        "        f\"{{\\n\"\n",
        "        f'  \"intent\": \"{intent}\",\\n'\n",
        "        f'  \"elements\": [{{ \"type\": \"...\", \"title\": \"...\", \"body\": \"...\" }}]\\n'\n",
        "        f\"}}\"\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"system_prompt\": system_prompt,\n",
        "        \"user_input\": user_prompt,\n",
        "        \"retrieval_context\": retrieval_context,\n",
        "        \"instructions\": \"\"  # not needed now; layout is embedded in user prompt\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXVKzOypRQg-"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gOVnCHIhJh7",
        "outputId": "5cf736b5-63ad-4f48-bfd3-2abaf6cacd9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- SYSTEM PROMPT ---\n",
            "You are a microsite generation assistant. Return a structured JSON response for a microsite with 5 elements. Each element must include: type, title, and body. Body must be <150 words.\n",
            "\n",
            "--- USER PROMPT ---\n",
            "Intent: Promote\n",
            "User Input: Promote my home-based custom cake business\n",
            "\n",
            "Retrieved Context:\n",
            "- Home-based dessert businesses see increased demand in summer events. (Industry Report)\n",
            "- Customers love personalized, handcrafted cakes. (Social Media Trends)\n",
            "\n",
            "Microsite layout:\n",
            "1. Informational\n",
            "2. Benefits\n",
            "3. Trend\n",
            "4. Cta\n",
            "5. Testimonial\n",
            "\n",
            "Respond in the following JSON format:\n",
            "{\n",
            "  \"intent\": \"Promote\",\n",
            "  \"elements\": [{ \"type\": \"...\", \"title\": \"...\", \"body\": \"...\" }]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Test the updated build_prompt function with promote intent\n",
        "test_prompt = build_prompt(\n",
        "    intent=\"Promote\",\n",
        "    user_input=\"Promote my home-based custom cake business\",\n",
        "    retrieval_context=[\n",
        "        \"Home-based dessert businesses see increased demand in summer events. (Industry Report)\",\n",
        "        \"Customers love personalized, handcrafted cakes. (Social Media Trends)\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Print the result for inspection\n",
        "print(\"--- SYSTEM PROMPT ---\")\n",
        "print(test_prompt[\"system_prompt\"])\n",
        "\n",
        "print(\"\\n--- USER PROMPT ---\")\n",
        "print(test_prompt[\"user_input\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fQGNsczd6gT"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def parse_and_validate_gpt_output(gpt_response_text: str, expected_intent: str, layout_types: list):\n",
        "    \"\"\"\n",
        "    Parse GPT output JSON text and validate the structure.\n",
        "    Returns:\n",
        "      - dict with parsed data if valid,\n",
        "      - else raises ValueError with error details.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = json.loads(gpt_response_text)\n",
        "    except json.JSONDecodeError as e:\n",
        "        raise ValueError(f\"Invalid JSON: {e}\")\n",
        "\n",
        "    # Check top-level keys\n",
        "    if \"intent\" not in data or \"elements\" not in data:\n",
        "        raise ValueError(\"JSON missing required keys 'intent' or 'elements'.\")\n",
        "\n",
        "    # Intent match check\n",
        "    if data[\"intent\"].lower() != expected_intent.lower():\n",
        "        raise ValueError(f\"Intent mismatch: expected '{expected_intent}', got '{data['intent']}'.\")\n",
        "\n",
        "    elements = data[\"elements\"]\n",
        "    if not isinstance(elements, list):\n",
        "        raise ValueError(\"'elements' should be a list.\")\n",
        "\n",
        "    # Validate elements length\n",
        "    if len(elements) != len(layout_types):\n",
        "        raise ValueError(f\"Number of elements {len(elements)} does not match layout length {len(layout_types)}.\")\n",
        "\n",
        "    # Validate each element\n",
        "    for i, el in enumerate(elements):\n",
        "        for key in (\"type\", \"title\", \"body\"):\n",
        "            if key not in el:\n",
        "                raise ValueError(f\"Element {i} missing key '{key}'.\")\n",
        "            if not isinstance(el[key], str) or not el[key].strip():\n",
        "                raise ValueError(f\"Element {i} key '{key}' must be a non-empty string.\")\n",
        "\n",
        "        # Check body word count < 150\n",
        "        word_count = len(el[\"body\"].split())\n",
        "        if word_count > 150:\n",
        "            raise ValueError(f\"Element {i} body exceeds 150 words ({word_count} words).\")\n",
        "\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yDCkqMviGOE"
      },
      "outputs": [],
      "source": [
        "def reorder_and_fill_elements(elements: list, layout_types: list):\n",
        "    \"\"\"\n",
        "    Reorder elements by layout_types.\n",
        "    Fill missing elements with placeholders.\n",
        "    \"\"\"\n",
        "    elements_map = {el[\"type\"].lower(): el for el in elements}\n",
        "    final_elements = []\n",
        "\n",
        "    for el_type in layout_types:\n",
        "        el_type_lower = el_type.lower()\n",
        "        if el_type_lower in elements_map:\n",
        "            final_elements.append(elements_map[el_type_lower])\n",
        "        else:\n",
        "            # Placeholder element if missing\n",
        "            final_elements.append({\n",
        "                \"type\": el_type_lower,\n",
        "                \"title\": f\"Placeholder Title for {el_type.title()}\",\n",
        "                \"body\": f\"This is placeholder content for the {el_type.title()} section.\"\n",
        "            })\n",
        "\n",
        "    return final_elements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnIcYwxViI6t",
        "outputId": "6e349d36-8c8f-478f-b031-3cc6fedaab43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validated and reordered microsite elements:\n",
            "{'intent': 'Promote', 'elements': [{'type': 'informational', 'title': 'Welcome to Sweet Treats Baking Studio', 'body': \"Located in the heart of Austin, our home baking studio specializes in custom cakes for all occasions. Whether it's a birthday, wedding, or any celebration, we craft delicious and beautiful cakes tailored to your vision.\"}, {'type': 'benefits', 'title': 'Why Choose Us?', 'body': 'Our cakes are made from the finest ingredients, ensuring rich flavors and moist textures. We offer personalized designs, quick turnaround times, and a commitment to quality that will make your event unforgettable.'}, {'type': 'trend', 'title': 'Summer Baking Boom', 'body': 'Home-based dessert businesses peak during summer due to high demand for custom cakes for events. This is the perfect time to order your cake and make your celebrations even sweeter!'}, {'type': 'CTA', 'title': 'Order Your Custom Cake Today!', 'body': 'Ready to make your next event special? Visit our Instagram page to see our latest creations and DM us to place your order. Let’s bake something amazing together!'}, {'type': 'testimonial', 'title': 'What Our Customers Say', 'body': '‘The cake was not only stunning but absolutely delicious! Sweet Treats made my birthday unforgettable. Highly recommend!’ - Sarah, Austin'}]}\n"
          ]
        }
      ],
      "source": [
        "# Assuming `gpt_response` is the raw JSON string from GPT\n",
        "\n",
        "intent = \"Promote\"\n",
        "layout = [\"informational\", \"benefits\", \"trend\", \"cta\", \"testimonial\"]\n",
        "\n",
        "try:\n",
        "    gpt_response = r.choices[0].message.content\n",
        "\n",
        "\n",
        "    parsed_data = parse_and_validate_gpt_output(gpt_response, intent, layout)\n",
        "    clean_elements = reorder_and_fill_elements(parsed_data[\"elements\"], layout)\n",
        "    parsed_data[\"elements\"] = clean_elements\n",
        "    print(\"Validated and reordered microsite elements:\")\n",
        "    print(parsed_data)\n",
        "except ValueError as e:\n",
        "    print(\"Error validating GPT output:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRoUtxeBiMHS",
        "outputId": "cb787bd7-7c42-487e-e3d7-96b7d9bffd84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Microsite Intent: Promote\n",
            "\n",
            "Microsite Elements:\n",
            "\n",
            "--- Element 1 ---\n",
            "Type: Informational\n",
            "Title: Welcome to Sweet Treats Baking Studio\n",
            "Body:\n",
            "Located in the heart of Austin, our home baking studio specializes in custom cakes for all occasions. Whether it's a birthday, wedding, or any celebration, we craft delicious and beautiful cakes tailored to your vision.\n",
            "\n",
            "--- Element 2 ---\n",
            "Type: Benefits\n",
            "Title: Why Choose Us?\n",
            "Body:\n",
            "Our cakes are made from the finest ingredients, ensuring rich flavors and moist textures. We offer personalized designs, quick turnaround times, and a commitment to quality that will make your event unforgettable.\n",
            "\n",
            "--- Element 3 ---\n",
            "Type: Trend\n",
            "Title: Summer Baking Boom\n",
            "Body:\n",
            "Home-based dessert businesses peak during summer due to high demand for custom cakes for events. This is the perfect time to order your cake and make your celebrations even sweeter!\n",
            "\n",
            "--- Element 4 ---\n",
            "Type: Cta\n",
            "Title: Order Your Custom Cake Today!\n",
            "Body:\n",
            "Ready to make your next event special? Visit our Instagram page to see our latest creations and DM us to place your order. Let’s bake something amazing together!\n",
            "\n",
            "--- Element 5 ---\n",
            "Type: Testimonial\n",
            "Title: What Our Customers Say\n",
            "Body:\n",
            "‘The cake was not only stunning but absolutely delicious! Sweet Treats made my birthday unforgettable. Highly recommend!’ - Sarah, Austin\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def print_microsite(microsite_data: dict):\n",
        "    print(f\"Microsite Intent: {microsite_data.get('intent', 'N/A').title()}\\n\")\n",
        "    print(\"Microsite Elements:\\n\")\n",
        "    for i, element in enumerate(microsite_data.get(\"elements\", []), start=1):\n",
        "        print(f\"--- Element {i} ---\")\n",
        "        print(f\"Type: {element.get('type', '').capitalize()}\")\n",
        "        print(f\"Title: {element.get('title', '')}\")\n",
        "        print(\"Body:\")\n",
        "        print(element.get('body', ''))\n",
        "        print()  # extra newline for spacing\n",
        "\n",
        "# Example usage:\n",
        "print_microsite(parsed_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCI_vQlt4JAF"
      },
      "source": [
        "# Set up API orchestration logic for dynamic calls to Mini\n",
        "This code cleans, fixes, and finalizes the microsite content generated by GPT, ensuring it's valid, complete, and in the correct format directly fulfilling layout engine and partially supporting prompt logic validation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCh3cb42oTFI",
        "outputId": "8bf8c30d-1b1e-4215-bedc-88bf950e95fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Microsite Intent: Promote\n",
            "Microsite Elements:\n",
            "\n",
            "--- Element 1 ---\n",
            "Type: Informational\n",
            "Title: Welcome to Sweet Treats Baking Studio\n",
            "Body:\n",
            "Located in the heart of Austin, our home baking studio specializes in custom cakes for all occasions. Whether it's a birthday, wedding, or any celebration, we craft delicious and beautiful cakes tailored to your vision.\n",
            "\n",
            "--- Element 2 ---\n",
            "Type: Benefits\n",
            "Title: Why Choose Us?\n",
            "Body:\n",
            "Our cakes are made from the finest ingredients, ensuring rich flavors and moist textures. We offer personalized designs, quick turnaround times, and a commitment to quality that will make your event unforgettable.\n",
            "\n",
            "--- Element 3 ---\n",
            "Type: Trend\n",
            "Title: Summer Baking Boom\n",
            "Body:\n",
            "Home-based dessert businesses peak during summer due to high demand for custom cakes for events. This is the perfect time to order your cake and make your celebrations even sweeter!\n",
            "\n",
            "--- Element 4 ---\n",
            "Type: Cta\n",
            "Title: Order Your Custom Cake Today!\n",
            "Body:\n",
            "Ready to make your next event special? Visit our Instagram page to see our latest creations and DM us to place your order. Let’s bake something amazing together!\n",
            "\n",
            "--- Element 5 ---\n",
            "Type: Testimonial\n",
            "Title: What Our Customers Say\n",
            "Body:\n",
            "‘The cake was not only stunning but absolutely delicious! Sweet Treats made my birthday unforgettable. Highly recommend!’ - Sarah, Austin\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from typing import List, Optional\n",
        "\n",
        "def parse_and_validate_gpt_output(gpt_response_text: str, expected_intent: str, layout_types: List[str]) -> dict:\n",
        "    \"\"\"\n",
        "    Parse GPT output JSON string and validate the structure and intent.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = json.loads(gpt_response_text)\n",
        "    except json.JSONDecodeError as e:\n",
        "        raise ValueError(f\"Invalid JSON: {e}\")\n",
        "\n",
        "    # Basic validation of keys\n",
        "    if \"intent\" not in data or \"elements\" not in data:\n",
        "        raise ValueError(\"Missing required keys 'intent' or 'elements' in GPT response\")\n",
        "\n",
        "    if data[\"intent\"].lower() != expected_intent.lower():\n",
        "        raise ValueError(f\"Intent mismatch: expected {expected_intent}, got {data['intent']}\")\n",
        "\n",
        "    if not isinstance(data[\"elements\"], list) or len(data[\"elements\"]) != len(layout_types):\n",
        "        raise ValueError(f\"Elements count mismatch: expected {len(layout_types)}, got {len(data['elements'])}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "def reorder_and_fill_elements(elements: List[dict], layout_types: List[str]) -> List[dict]:\n",
        "    \"\"\"\n",
        "    Reorder elements according to layout_types and fill any missing with placeholders.\n",
        "    \"\"\"\n",
        "    elements_dict = {el['type'].lower(): el for el in elements}\n",
        "\n",
        "    reordered = []\n",
        "    for lt in layout_types:\n",
        "        el = elements_dict.get(lt.lower())\n",
        "        if el is None:\n",
        "            el = {\n",
        "                \"type\": lt,\n",
        "                \"title\": f\"Placeholder for {lt.title()}\",\n",
        "                \"body\": \"Content coming soon.\"\n",
        "            }\n",
        "        reordered.append(el)\n",
        "    return reordered\n",
        "\n",
        "def orchestrate(intent: str,\n",
        "                user_input: str,\n",
        "                gpt_raw_response,\n",
        "                layout: List[str],\n",
        "                retrieval_context: Optional[List[str]] = None):\n",
        "    \"\"\"\n",
        "    Orchestrate the microsite generation pipeline using the existing GPT response 'gpt_raw_response'.\n",
        "\n",
        "    Parameters:\n",
        "    - intent: The microsite intent string (e.g., \"Promote\").\n",
        "    - user_input: The user's initial input prompt.\n",
        "    - gpt_raw_response: The raw GPT API response object (already obtained).\n",
        "    - layout: The list of element types defining the microsite layout.\n",
        "    - retrieval_context: Optional list of retrieved context strings.\n",
        "\n",
        "    Returns:\n",
        "    - Parsed, validated, and reordered microsite elements as a dictionary.\n",
        "    \"\"\"\n",
        "    # Extract GPT-generated content string from the response object\n",
        "    content = gpt_raw_response.choices[0].message.content.strip()\n",
        "\n",
        "    # Parse and validate the GPT output JSON string\n",
        "    parsed_data = parse_and_validate_gpt_output(content, expected_intent=intent, layout_types=layout)\n",
        "\n",
        "    # Reorder elements according to the layout and fill missing ones with placeholders if any\n",
        "    clean_elements = reorder_and_fill_elements(parsed_data[\"elements\"], layout)\n",
        "    parsed_data[\"elements\"] = clean_elements\n",
        "\n",
        "    # (Optional) Add enrichment or Serper API calls here if needed in future\n",
        "\n",
        "    return parsed_data\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "LAYOUT_PROMOTE = [\"informational\", \"benefits\", \"trend\", \"cta\", \"testimonial\"]\n",
        "\n",
        "final_output = orchestrate(\n",
        "    intent=\"Promote\",\n",
        "    user_input=\"Promote my home-based custom cake business\",\n",
        "    gpt_raw_response=r,  # Your GPT raw response stored earlier\n",
        "    layout=LAYOUT_PROMOTE,\n",
        "    retrieval_context=[\n",
        "        \"Home-based dessert businesses see increased demand in summer events. (Industry Report)\",\n",
        "        \"Customers love personalized, handcrafted cakes. (Social Media Trends)\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "# You can then print or further process final_output as needed:\n",
        "print(\"Microsite Intent:\", final_output[\"intent\"])\n",
        "print(\"Microsite Elements:\\n\")\n",
        "for idx, el in enumerate(final_output[\"elements\"], start=1):\n",
        "    print(f\"--- Element {idx} ---\")\n",
        "    print(f\"Type: {el['type'].title()}\")\n",
        "    print(f\"Title: {el['title']}\")\n",
        "    print(f\"Body:\\n{el['body']}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQqt4pzq4Yb-"
      },
      "source": [
        "#Build caching middleware for prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdOVmMLitw-q",
        "outputId": "0ba7d8ec-dd8a-47b4-abd7-0e6b0abbec69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Microsite Intent: Promote\n",
            "\n",
            "Microsite Elements:\n",
            "\n",
            "--- Element 1 ---\n",
            "Type: Informational\n",
            "Title: Welcome to Your Custom Cake Destination\n",
            "Body:\n",
            "At our home-based cake business in Austin, we specialize in creating custom cakes for every occasion. Whether it's a birthday, wedding, or a summer gathering, our cakes are made from the finest ingredients and tailored to your unique vision. Explore our delicious offerings and let us help you celebrate life's special moments with a sweet touch!\n",
            "\n",
            "--------------------\n",
            "--- Element 2 ---\n",
            "Type: Benefits\n",
            "Title: Why Choose Our Custom Cakes?\n",
            "Body:\n",
            "Choosing our custom cakes means opting for quality, personalization, and creativity. We offer a wide variety of flavors and designs, ensuring that your cake is as unique as your event. Our home-based approach allows for fresh, made-to-order cakes that cater to dietary needs, ensuring everyone can enjoy a slice of happiness this summer!\n",
            "\n",
            "--------------------\n",
            "--- Element 3 ---\n",
            "Type: Trend\n",
            "Title: Summer Baking Trends\n",
            "Body:\n",
            "This summer, custom cakes are in high demand for events like graduations, weddings, and outdoor parties. Our cakes not only taste fantastic but are also designed to be Instagram-ready. Join the trend by ordering a cake that will elevate your celebrations and make your social media feed pop!\n",
            "\n",
            "--------------------\n",
            "--- Element 4 ---\n",
            "Type: Cta\n",
            "Title: Order Your Custom Cake Today!\n",
            "Body:\n",
            "Ready to indulge in a delicious custom cake? Contact us now to discuss your ideas and place your order! Don’t forget to follow us on Instagram for behind-the-scenes baking videos, cake inspiration, and special summer promotions. Let's make your next event unforgettable!\n",
            "\n",
            "--------------------\n",
            "--- Element 5 ---\n",
            "Type: Testimonial\n",
            "Title: What Our Customers Say\n",
            "Body:\n",
            "“The cake we ordered for our daughter's birthday was a showstopper! Not only did it look amazing, but it was the best cake we’ve ever tasted. Everyone was asking where we got it from. Highly recommend!” - Sarah, Austin\n",
            "\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from typing import List, Optional\n",
        "import logging\n",
        "import hashlib\n",
        "import os\n",
        "import time # Import time for retries\n",
        "\n",
        "# Ensure logging is configured if it hasn't been already\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "\n",
        "# Assuming these are defined elsewhere in the notebook\n",
        "# from openai import OpenAI\n",
        "# client = OpenAI(...)\n",
        "CACHE_DIR = \"./cache_microsite\"\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "# Redefine utility functions if they are not available in the current cell block\n",
        "def get_cache_key(prompt_config: dict) -> str:\n",
        "    key_string = json.dumps({\n",
        "        \"system_prompt\": prompt_config.get(\"system_prompt\", \"\"),\n",
        "        \"user_input\": prompt_config.get(\"user_input\", \"\"),\n",
        "        \"retrieval_context\": prompt_config.get(\"retrieval_context\", []),\n",
        "        \"nano_output\": prompt_config.get(\"nano_output\", {}),\n",
        "        \"instructions\": prompt_config.get(\"instructions\", \"\")\n",
        "    }, sort_keys=True)\n",
        "    return hashlib.sha256(key_string.encode('utf-8')).hexdigest()\n",
        "\n",
        "def load_from_cache(cache_key: str):\n",
        "    cache_path = os.path.join(CACHE_DIR, f\"{cache_key}.json\")\n",
        "    if os.path.isfile(cache_path):\n",
        "        try:\n",
        "            with open(cache_path, \"r\") as f:\n",
        "                return json.load(f)\n",
        "        except Exception as e:\n",
        "            logging.warning(f\"Failed to load cache file {cache_path}: {e}\")\n",
        "    return None\n",
        "\n",
        "def save_to_cache(cache_key: str, data: dict):\n",
        "    cache_path = os.path.join(CACHE_DIR, f\"{cache_key}.json\")\n",
        "    try:\n",
        "        with open(cache_path, \"w\") as f:\n",
        "            json.dump(data, f, indent=2)\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"Failed to save cache file {cache_path}: {e}\")\n",
        "\n",
        "def generate_microsite_with_gpt(prompt_config: dict, max_tokens: int = 500): # Increased default max_tokens\n",
        "    \"\"\"\n",
        "    Makes a gpt-4o-mini call with caching and returns parsed JSON dictionary or error dict.\n",
        "    \"\"\"\n",
        "    if not prompt_config.get(\"system_prompt\"):\n",
        "        logging.error(\"Prompt configuration is incomplete or invalid.\")\n",
        "        return {\"error\": \"Prompt configuration invalid.\"}\n",
        "\n",
        "    # Cache key includes relevant prompt components\n",
        "    cache_key = get_cache_key(prompt_config)\n",
        "    cached_response_dict = load_from_cache(cache_key)\n",
        "    if cached_response_dict:\n",
        "        logging.info(\"Using cached GPT response.\")\n",
        "        return cached_response_dict # Return dictionary directly\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": prompt_config[\"system_prompt\"]},\n",
        "        {\"role\": \"user\", \"content\": prompt_config[\"user_input\"]}\n",
        "    ]\n",
        "\n",
        "    # Add retrieval context and nano output if present\n",
        "    if prompt_config.get(\"retrieval_context\"):\n",
        "        messages.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Retrieved Context:\\n\" + \"\\n\".join(f\"- {line}\" for line in prompt_config[\"retrieval_context\"])\n",
        "        })\n",
        "\n",
        "    if prompt_config.get(\"nano_output\"):\n",
        "        messages.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Image Analysis:\\n{json.dumps(prompt_config['nano_output'], indent=2)}\"\n",
        "        })\n",
        "\n",
        "    # Add explicit instructions if present\n",
        "    if prompt_config.get(\"instructions\"):\n",
        "         messages.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt_config[\"instructions\"]\n",
        "        })\n",
        "\n",
        "\n",
        "    try:\n",
        "        logging.info(\"Calling OpenAI API...\")\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=messages,\n",
        "            temperature=0.7, # Slightly increased temperature for variety, adjust as needed\n",
        "            top_p=0.9,\n",
        "            max_tokens=max_tokens, # Use passed max_tokens\n",
        "            response_format={ \"type\": \"json_object\" } # Explicitly request JSON output type\n",
        "        )\n",
        "        content = response.choices[0].message.content.strip()\n",
        "\n",
        "        try:\n",
        "            # Attempt to parse JSON\n",
        "            parsed_json_from_api = json.loads(content)\n",
        "            # Save successful parsed JSON to cache\n",
        "            save_to_cache(cache_key, parsed_json_from_api)\n",
        "            # Return the parsed dictionary\n",
        "            return parsed_json_from_api\n",
        "        except json.JSONDecodeError as e:\n",
        "            logging.error(f\"JSON Decode Error: {e}\")\n",
        "            logging.error(f\"Content received from API was:\\n{content}\") # Print raw content for debugging\n",
        "            # Return an error dictionary including the raw content\n",
        "            return {\"error\": \"Failed to parse JSON response from AI.\", \"raw_content\": content}\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error during OpenAI API call: {e}\")\n",
        "        # Return an error dictionary\n",
        "        return {\"error\": f\"OpenAI API call failed: {e}\"}\n",
        "\n",
        "\n",
        "def parse_and_validate_gpt_output(gpt_data: dict, expected_intent: str, layout_types: List[str]) -> dict:\n",
        "    \"\"\"\n",
        "    Validate the structure and intent of a *parsed* GPT output dictionary.\n",
        "    \"\"\"\n",
        "    # Input 'gpt_data' is already a dictionary\n",
        "\n",
        "    # Basic validation of keys\n",
        "    if \"intent\" not in gpt_data or \"elements\" not in gpt_data:\n",
        "        raise ValueError(\"Missing required keys 'intent' or 'elements' in GPT response dictionary\")\n",
        "\n",
        "    # Validate intent (case-insensitive match)\n",
        "    if gpt_data.get(\"intent\", \"\").lower() != expected_intent.lower():\n",
        "        raise ValueError(f\"Intent mismatch: expected '{expected_intent}', got '{gpt_data.get('intent')}'.\")\n",
        "\n",
        "    elements = gpt_data[\"elements\"]\n",
        "    if not isinstance(elements, list):\n",
        "         raise ValueError(\"'elements' should be a list.\")\n",
        "\n",
        "\n",
        "    # Validate each element structure (type, title, body)\n",
        "    for i, el in enumerate(elements):\n",
        "        if not isinstance(el, dict):\n",
        "            raise ValueError(f\"Element {i} is not a dictionary.\")\n",
        "\n",
        "        # Use .get() for safer access during validation\n",
        "        el_type = el.get(\"type\")\n",
        "        el_title = el.get(\"title\")\n",
        "        el_body = el.get(\"body\")\n",
        "\n",
        "        if not isinstance(el_type, str) or not el_type.strip():\n",
        "             logging.warning(f\"Element {i} missing or invalid 'type'. Got: {el_type}\")\n",
        "             # Optionally raise error if type is mandatory\n",
        "             # raise ValueError(f\"Element {i} missing or invalid 'type'.\")\n",
        "\n",
        "        if not isinstance(el_title, str) or not el_title.strip():\n",
        "             logging.warning(f\"Element {i} missing or invalid 'title'. Got: {el_title}\")\n",
        "             # Optionally raise error\n",
        "             # raise ValueError(f\"Element {i} missing or invalid 'title'.\")\n",
        "\n",
        "\n",
        "        if not isinstance(el_body, str):\n",
        "             logging.warning(f\"Element {i} missing or invalid 'body'. Expected string, got: {type(el_body)}\")\n",
        "             # Optionally raise error\n",
        "             # raise ValueError(f\"Element {i} missing or invalid 'body'. Expected string.\")\n",
        "\n",
        "        # Check body word count < 150 if body is a string\n",
        "        if isinstance(el_body, str):\n",
        "            word_count = len(el_body.split())\n",
        "            if word_count > 150:\n",
        "                logging.warning(f\"Element {i} body exceeds 150 words ({word_count} words).\")\n",
        "                # Optionally raise an error if strict\n",
        "                # raise ValueError(f\"Element {i} body exceeds 150 words ({word_count} words).\")\n",
        "\n",
        "\n",
        "    # Return the validated dictionary\n",
        "    return gpt_data\n",
        "\n",
        "\n",
        "def reorder_and_fill_elements(elements: List[dict], layout_types: List[str]) -> List[dict]:\n",
        "    \"\"\"\n",
        "    Reorder elements according to layout_types and fill any missing with placeholders.\n",
        "    Assumes input elements list might not be complete or correctly ordered.\n",
        "    Handles potential non-dictionary elements gracefully.\n",
        "    \"\"\"\n",
        "    # Create a dictionary mapping lowercase element type from input to the element dict\n",
        "    elements_dict = {}\n",
        "    for el in elements:\n",
        "        if isinstance(el, dict):\n",
        "            el_type = el.get('type')\n",
        "            if isinstance(el_type, str) and el_type.strip():\n",
        "                 elements_dict[el_type.strip().lower()] = el\n",
        "            else:\n",
        "                 logging.warning(f\"Skipping element in reordering due to missing or invalid 'type': {el}\")\n",
        "        else:\n",
        "            logging.warning(f\"Skipping non-dictionary item in elements list: {el}\")\n",
        "\n",
        "\n",
        "    reordered = []\n",
        "    for lt in layout_types:\n",
        "        lt_lower = lt.lower()\n",
        "        el = elements_dict.get(lt_lower)\n",
        "        if el is None:\n",
        "            # Placeholder element if missing in the GPT output or invalid input\n",
        "            reordered.append({\n",
        "                \"type\": lt_lower, # Use lowercase for consistency\n",
        "                \"title\": f\"Placeholder for {lt.title()}\",\n",
        "                \"body\": \"Content coming soon.\"\n",
        "            })\n",
        "        else:\n",
        "            # Use the element from GPT output, but ensure type is lowercase and strip whitespace\n",
        "            el['type'] = el.get('type', '').strip().lower()\n",
        "            # Ensure title and body are strings, provide defaults if needed\n",
        "            el['title'] = str(el.get('title', '')).strip()\n",
        "            el['body'] = str(el.get('body', '')).strip()\n",
        "            reordered.append(el)\n",
        "    return reordered\n",
        "\n",
        "\n",
        "def orchestrate(prompt_config: dict, intent: str, layout: List[str], retries: int = 3, delay: int = 5):\n",
        "    \"\"\"\n",
        "    Orchestrate microsite generation workflow with retries.\n",
        "    Uses the cache-enabled GPT call function.\n",
        "    Parses, validates, and reorders elements.\n",
        "    \"\"\"\n",
        "    for attempt in range(retries):\n",
        "        logging.info(f\"Attempt {attempt + 1}/{retries} to generate microsite.\")\n",
        "\n",
        "        # Call GPT with caching enabled - this function now returns a dictionary\n",
        "        microsite_data = generate_microsite_with_gpt(prompt_config)\n",
        "\n",
        "        # Check if generate_microsite_with_gpt returned an error dictionary\n",
        "        if \"error\" in microsite_data:\n",
        "            logging.error(f\"Attempt {attempt + 1} failed: GPT microsite generation failed or returned invalid JSON string.\")\n",
        "            logging.error(f\"Error details: {microsite_data.get('error', 'Unknown Error')}\")\n",
        "            if \"raw_content\" in microsite_data:\n",
        "                 logging.error(f\"Raw content from API:\\n{microsite_data['raw_content']}\")\n",
        "\n",
        "            if attempt < retries - 1:\n",
        "                logging.info(f\"Retrying in {delay} seconds...\")\n",
        "                time.sleep(delay)\n",
        "                continue # Try the next attempt\n",
        "\n",
        "            # If this was the last attempt, return the error\n",
        "            logging.error(\"Max retries reached. Failed to generate valid microsite data.\")\n",
        "            return microsite_data # Return the final error dictionary\n",
        "\n",
        "        # If no error from generate_microsite_with_gpt, proceed to validation and processing\n",
        "        try:\n",
        "            # Validate the structure of the parsed dictionary\n",
        "            validated_data = parse_and_validate_gpt_output(microsite_data, intent, layout)\n",
        "\n",
        "            # Reorder elements based on layout and fill missing ones\n",
        "            clean_elements = reorder_and_fill_elements(validated_data.get(\"elements\", []), layout) # Use .get() for safety\n",
        "            validated_data[\"elements\"] = clean_elements\n",
        "\n",
        "            logging.info(\"Microsite data generated and validated successfully.\")\n",
        "            return validated_data # Success! Return the processed data\n",
        "\n",
        "        except ValueError as e:\n",
        "            logging.error(f\"Attempt {attempt + 1} failed: Validation or processing error: {e}\")\n",
        "            # Log the raw data that caused the validation error\n",
        "            logging.error(f\"Data causing validation error:\\n{json.dumps(microsite_data, indent=2)}\")\n",
        "\n",
        "            if attempt < retries - 1:\n",
        "                logging.info(f\"Retrying in {delay} seconds...\")\n",
        "                time.sleep(delay)\n",
        "                continue # Try the next attempt\n",
        "\n",
        "            # If this was the last attempt and validation failed, return an error\n",
        "            logging.error(\"Max retries reached. Failed to validate generated microsite data.\")\n",
        "            return {\"error\": f\"Microsite data validation failed after retries: {e}\", \"raw_data\": microsite_data}\n",
        "\n",
        "    # This part should theoretically not be reached if retries > 0, but included as fallback\n",
        "    return {\"error\": \"Orchestration failed after retries.\"}\n",
        "\n",
        "\n",
        "# Assuming LAYOUT_PROMOTE is defined elsewhere or define it here if needed\n",
        "LAYOUT_PROMOTE = [\"informational\", \"benefits\", \"trend\", \"cta\", \"testimonial\"]\n",
        "\n",
        "intent = \"Promote\"\n",
        "layout = LAYOUT_PROMOTE # Use the defined layout variable\n",
        "\n",
        "# Define user input and retrieval context\n",
        "user_input = \"Promote my home-based custom cake business in Austin to increase Instagram cake orders this summer.\"\n",
        "retrieval_context = [\n",
        "    \"Home-based dessert businesses peak during summer due to custom event demand. (Reddit)\",\n",
        "    \"Instagram Reels showing behind-the-scenes baking have high engagement. (Quora)\"\n",
        "]\n",
        "\n",
        "# Call build_prompt to generate the prompt_config\n",
        "prompt_config = build_prompt(\n",
        "    intent=intent,\n",
        "    user_input=user_input,\n",
        "    retrieval_context=retrieval_context\n",
        ")\n",
        "\n",
        "\n",
        "# Assuming 'client' and 'logging' are initialized correctly in the notebook environment\n",
        "# Assuming CACHE_DIR and os.makedirs(CACHE_DIR, exist_ok=True) are run\n",
        "\n",
        "# Call the updated orchestrate function with retries\n",
        "result = orchestrate(prompt_config, intent, layout, retries=5, delay=10) # Added retries and delay\n",
        "\n",
        "\n",
        "# Print the result nicely or handle errors\n",
        "if \"error\" not in result:\n",
        "    print(f\"Microsite Intent: {result.get('intent', 'N/A')}\\n\")\n",
        "    print(\"Microsite Elements:\\n\")\n",
        "    # Use get with default empty list in case 'elements' key is missing after processing\n",
        "    for idx, el in enumerate(result.get(\"elements\", []), 1):\n",
        "        print(f\"--- Element {idx} ---\")\n",
        "        # Use get with default 'N/A' for safer access to element keys\n",
        "        print(f\"Type: {el.get('type', 'N/A').capitalize()}\")\n",
        "        print(f\"Title: {el.get('title', 'N/A')}\")\n",
        "        print(\"Body:\")\n",
        "        print(el.get('body', 'N/A'))\n",
        "        print(\"\\n\" + \"-\"*20) # Add a separator\n",
        "else:\n",
        "    print(\"Error orchestrating microsite:\")\n",
        "    print(f\"Error message: {result.get('error', 'Unknown error')}\")\n",
        "    # Print raw data/content if available in the error dictionary\n",
        "    if \"raw_data\" in result:\n",
        "        print(\"\\nRaw Data (if available):\")\n",
        "        # Use json.dumps for pretty printing the dictionary\n",
        "        print(json.dumps(result[\"raw_data\"], indent=2))\n",
        "    elif \"raw_content\" in result:\n",
        "         print(\"\\nRaw Content (if available):\")\n",
        "         print(result[\"raw_content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFQyjuZemP_8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
